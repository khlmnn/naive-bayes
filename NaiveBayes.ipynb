{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their affiliation to a political block (right-wing/left-wing). The specific texts you are going to classify are speeches held in the Swedish parliament. The classifier will take in a speech and predict if the speaker belongs to a right-wing or a left-wing party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start this lab by importing the Python module `nb`, which contains the implementation of a very simple Naive Bayes classifier as well as some helper functions that you will use in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this lab consists of all speeches held in the Swedish parliament in the 2016/2017 and 2017/2018 sessions. The raw data is taken from [Riksdag's open data](http://data.riksdagen.se/). Speeches are divided into two (compressed) text files:\n",
    "\n",
    "* `anforande-201617.txt.bz2` with 12,637 speeches\n",
    "* `anforande-201718.txt.bz2` with 12,343 speeches\n",
    "\n",
    "In order to read the data files, we use the helper function `read_data()` from the `nb` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_201617 = nb.read_data(\"anforande-201617.txt.bz2\")\n",
    "speeches_201718 = nb.read_data(\"anforande-201718.txt.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a speech is represented as a pair consisting of\n",
    "\n",
    "* a string representing the gold-standard class for the speech: either `'L'` (left) or `'R'` (right)\n",
    "* a list of strings representing the words in the speech\n",
    "\n",
    "The code in the next cell prints an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speeches_201718[42])    # Change the 42 to any other number to see other examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Task 1</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>Have a look at a few examples from the data. Try to find examples from both classes. Would you have guessed the correct class, based on the words?</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "To work on this task, modify the code cell above and execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Train and evaluate a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell creates a new Naive Bayes classifier and trains it on the speeches from the 2016/17 session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nb.Classifier.train(speeches_201617)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the trained classifier to predict the class for a new speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_class, text = speeches_201718[42]\n",
    "print(\"The classifier predicts class\", classifier.predict(text))\n",
    "print(\"The gold-standard class is\", gold_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was it correct? Your next task is to evaluate the classifier with respect to accuracy. Remember that accuracy is defined as the percentage of instances for which the classifier predicts the correct class, according to the gold standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Task 2</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>Compute the accuracy of the trained classifier on the speeches from the 2017/2018 session.</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "To solve this problem you can use the function `nb.accuracy()` from the lab module. This function takes two arguments, a classifier and a list of gold-standard samples, and returns the accuracy of the classifier on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code for Task 1 into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare to a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy should not be understood as an absolute measure of performance &ndash; it makes sense only when used to compare a classifier against a **baseline**. In the absence of more meaningful alternatives, a simple baseline is *Most Frequent Class* &ndash; predict that class which appears most often in the training data â€“ without even looking at the words that appear in this data. We would hope that any classifier has a higher accuracy than this simple baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Task 3</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>Compute the accuracy for the Most Frequent Class baseline.</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "To solve this problem you can use the function `nb.baseline_accuracy()` from the lab module. This function takes two lists of gold-standard samples, one training set and one test set. It computes the most frequent class on the training set and return the corresponding baseline accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code for Task 2 into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last task in this lab is to reflect on general machine learning methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Task 4 (Reflection)</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>Redo the evaluation in Task&nbsp;2, but this time, compute the accuracy of the trained classifier on the speeches from 2016/2017. Take a note of the result and write a short reflection piece about your experience (ca. 150&nbsp;words). Use the following prompts:</p>\n",
    "    <ul>\n",
    "        <li>What accuracy did you get? Compare it to the accuracy that you got when you evaluated on the speeches from 2017/2018.</li>\n",
    "        <li>How can you explain your results based on your understanding of general machine learning methodology?</li>\n",
    "        <li>What did you learn from this experiment? How, exactly, did you learn it? Why does this learning matter?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code for Task 3 into this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done with your text, send it to [Marco](mailto:marco.kuhlmann@liu.se) via email. If you have worked as a pair on this lab, each of you will have to send her or his own text. You are of course welcome to discuss the result with your lab partner!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
